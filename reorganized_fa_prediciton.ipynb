{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook is aimed to reorganized prediction data,specificly:\n",
    "1. find the optimized PCs that should be ommited form prediction\n",
    "2. constrain the bootstrap procedure according to the standard prediction pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from algo import *\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import LeaveOneOut,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data path\n",
    "path = '/nfs/s2/userhome/yanganmin/workingdir/attention_data_complete/train_test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fa train and test data, also test on sa\n",
    "train_X_fa = np.load(os.path.join(path,'train_X_fa.npy'))\n",
    "test_X_fa = np.load(os.path.join(path,'test_X_fa.npy'))\n",
    "train_Y_fa = np.load(os.path.join(path,'train_Y_fa.npy'))\n",
    "test_Y_fa = np.load(os.path.join(path,'test_Y_fa.npy'))\n",
    "X_sa = np.load(os.path.join(path,'X_sa.npy'))\n",
    "Y_sa = np.load(os.path.join(path,'Y_sa.npy'))\n",
    "\n",
    "mask_NaN = np.load(os.path.join(path,'mask_NaN.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA of X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PCs is 314, which is also the number of observations in train_X_fa\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "train_X_fa = scale(train_X_fa)\n",
    "test_X_fa = scale(test_X_fa)\n",
    "X_sa = scale(X_sa)\n",
    "\n",
    "# reduce dimention with PCA\n",
    "pca = PCA() # reduce dimentions to the number of observations\n",
    "pca.fit(train_X_fa)\n",
    "train_X_fa_pc = pca.transform(train_X_fa)\n",
    "test_X_fa_pc = pca.transform(test_X_fa)\n",
    "X_sa_pc = pca.transform(X_sa)\n",
    "\n",
    "print(f'The number of PCs is {train_X_fa_pc.shape[1]}, which is also the number of observations in train_X_fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for the best hyper-Parameter\n",
    "the best c in Logistic regression using L1 penalty, based on train_X_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-Parameter C is 0.05.\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': np.arange(0.05,1.05,0.05)}]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l1',solver='liblinear'),tuned_parameters,cv=10,scoring='f1')\n",
    "clf.fit(train_X_fa_pc, train_Y_fa)\n",
    "\n",
    "C_best = clf.best_params_['C']\n",
    "\n",
    "print(f'Best hyper-Parameter C is {C_best}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1',solver='liblinear',C=C_best) # C value determined by grid search\n",
    "loo = LeaveOneOut()\n",
    "LR_beta = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LR to find PCs with low beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the LR_beta_mean is (314,).\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in loo.split(train_X_fa):\n",
    "    clf.fit(train_X_fa_pc[train_index], train_Y_fa[train_index])\n",
    "    LR_beta.append(clf.coef_[0])\n",
    "\n",
    "LR_beta_matrix = np.zeros(len(LR_beta[0]))\n",
    "for array in LR_beta:\n",
    "    LR_beta_matrix = np.vstack((LR_beta_matrix,array))\n",
    "LR_beta_matrix = LR_beta_matrix[1:,:]\n",
    "LR_beta_mean = LR_beta_matrix.mean(axis=0)\n",
    "print(f'the shape of the LR_beta_mean is {LR_beta_mean.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradually rule out PCs with low beta \n",
    "for-loop to dermine the best cutoff for beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_record = {} # dictionary to store predicition accuracy with each phase of reduction of PCs\n",
    "num_PC = []\n",
    "for beta_cutoff in np.arange(0,np.max(abs(LR_beta_mean)),0.001):\n",
    "    mask_beta = (abs(LR_beta_mean) > beta_cutoff)\n",
    "    train_X_fa_masked = train_X_fa_pc[:,mask_beta]\n",
    "    test_X_fa_masked = test_X_fa_pc[:,mask_beta]\n",
    "    \n",
    "    clf.fit(train_X_fa_masked,train_Y_fa)\n",
    "    \n",
    "    num_PC_temp = np.sum(mask_beta)\n",
    "    num_PC.append(num_PC_temp)\n",
    "    acc = clf.score(test_X_fa_masked,test_Y_fa)\n",
    "    PC_record[str(beta_cutoff)] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_pd = pd.DataFrame({'beta_cutoff':PC_record.keys(),\n",
    "                     'accuracy':PC_record.values(),\n",
    "                     'num_PC':num_PC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_cutoff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>num_PC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  beta_cutoff  accuracy  num_PC\n",
       "0         0.0  0.955128     120\n",
       "1       0.001  0.955128      64\n",
       "2       0.002  0.961538      54\n",
       "3       0.003  0.961538      48\n",
       "4       0.004  0.955128      46"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/nfs/s2/userhome/yanganmin/workingdir/attention_reorganized_results/'\n",
    "pc_pd.to_csv(os.path.join(save_path,'pc_selection','fa_pc_selection.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_cutoff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>num_PC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta_cutoff  accuracy  num_PC\n",
       "10        0.01  0.974359      25\n",
       "11       0.011  0.974359      24\n",
       "12       0.012  0.974359      23"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_pd[pc_pd['accuracy'] == pc_pd.max()['accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_cutoff_optimized = 0.01 # let beta cutoff be 0.01 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# employ new X with mask of optimized beta cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_beta_optimized = (abs(LR_beta_mean) > beta_cutoff_optimized)\n",
    "train_X_fa_optimized = train_X_fa_pc[:,mask_beta_optimized]\n",
    "test_X_fa_optimized = test_X_fa_pc[:,mask_beta_optimized]\n",
    "X_sa_optimized = X_sa_pc[:,mask_beta_optimized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save beta cutoff mask \n",
    "np.save(os.path.join(save_path,'pc_selection','train_fa_pc_mask.npy'),mask_beta_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1',solver='liblinear',C=C_best) # C value determined by grid search\n",
    "\n",
    "beta_pool = []\n",
    "loo = LeaveOneOut()\n",
    "leave_out_result = [] # tupple inside (train_accuracy,val_accuracy,test_accuracy)\n",
    "sa_result = []\n",
    "\n",
    "for train_index, test_index in loo.split(train_X_fa_optimized):\n",
    "    clf.fit(train_X_fa_optimized[train_index], train_Y_fa[train_index])\n",
    "\n",
    "    coef = clf.coef_[0]\n",
    "    coef_modified = mask_back(mask_beta,coef,mask_type='beta')\n",
    "    beta_fa = pca.inverse_transform(coef_modified)\n",
    "    beta_pool.append(beta_fa)\n",
    "\n",
    "    val_accuracy =  clf.score(train_X_fa_optimized[test_index], train_Y_fa[test_index])\n",
    "    train_accuracy = clf.score(train_X_fa_optimized[train_index],train_Y_fa[train_index])\n",
    "    test_accuracy = clf.score(test_X_fa_optimized,test_Y_fa)\n",
    "    leave_out_result.append((train_accuracy,val_accuracy,test_accuracy))\n",
    "\n",
    "    sa_result.append(clf.score(X_sa_optimized,Y_sa))\n",
    "\n",
    "# predict accuracy\n",
    "train_acc_array = [i[0] for i in leave_out_result]\n",
    "val_acc_array = [i[1] for i in leave_out_result]\n",
    "test_acc_array = [i[2] for i in leave_out_result]\n",
    "\n",
    "# save prediction results\n",
    "train_result = np.array(train_acc_array)\n",
    "val_result = np.array(val_acc_array)\n",
    "test_result = np.array(test_acc_array)\n",
    "sa_result = np.array(sa_result)\n",
    "result_matrix = np.c_[train_result,val_result,test_result,sa_result]\n",
    "df_result = pd.DataFrame(result_matrix, columns=['train','val','test','sa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>sa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.651064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.99361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.651064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.99361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.651064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.99361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.651064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.651064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train  val      test        sa\n",
       "0  0.99361  1.0  0.974359  0.651064\n",
       "1  0.99361  1.0  0.974359  0.651064\n",
       "2  0.99361  1.0  0.974359  0.651064\n",
       "3  0.99361  1.0  0.974359  0.651064\n",
       "4  0.99361  1.0  0.974359  0.651064"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(os.path.join(save_path,'predict_results','train_fa.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average beta value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_beta = np.zeros(beta_pool[0].shape[0])\n",
    "\n",
    "for pool in beta_pool:\n",
    "    avg_beta = np.vstack((avg_beta,pool))\n",
    "avg_beta = avg_beta[1:,:]\n",
    "avg_beta = avg_beta.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back-project beta map to mni space\n",
    "coef_mni = mask_back(mask_NaN,avg_beta,mask_type='mni')\n",
    "coef_mni = np.nan_to_num(coef_mni) # convert nan to zero\n",
    "nif_beta_raw = to_mni(coef_mni)\n",
    "nib.save(nif_beta_raw, os.path.join(save_path,'beta','fa_beta_nan_transferred.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap for beta distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "sample_size = 1000\n",
    "boot_coef = np.zeros(mask_NaN.shape[0])\n",
    "concat_data = np.c_[train_X_fa,train_Y_fa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 314 but corresponding boolean dimension is 149270",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-775ddf53ff1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmask_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR_beta_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbeta_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtrain_X_fa_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_beta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtest_X_fa_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X_fa_pc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_beta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_fa_masked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 314 but corresponding boolean dimension is 149270"
     ]
    }
   ],
   "source": [
    "full_start = time.time()\n",
    "\n",
    "# the bootstrap procedure should follow the aforementioned scheme Â \n",
    "for iteration in range(sample_size):\n",
    "    start = time.time()\n",
    "    \n",
    "    bootstraped_data = bootstrap_data(concat_data)\n",
    "    X = bootstraped_data[:,:-1] \n",
    "    Y = bootstraped_data[:,-1]           \n",
    "    \n",
    "    # average beta \n",
    "    LR_beta = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        clf.fit(X[train_index], Y[train_index])\n",
    "        LR_beta.append(clf.coef_[0])\n",
    "\n",
    "    LR_beta_matrix = np.zeros(len(LR_beta[0]))\n",
    "    for array in LR_beta:\n",
    "        LR_beta_matrix = np.vstack((LR_beta_matrix,array))\n",
    "    LR_beta_matrix = LR_beta_matrix[1:,:]\n",
    "    LR_beta_mean = LR_beta_matrix.mean(axis=0)\n",
    "    \n",
    "    # determine PCs to be ruled \n",
    "    beta_cutoff_pool = np.arange(0,np.max(abs(LR_beta_mean)),0.01)\n",
    "    acc_pool = []\n",
    "    for beta_cutoff in np.arange(0,np.max(abs(LR_beta_mean)),0.01):\n",
    "        mask_beta = (abs(LR_beta_mean) > beta_cutoff)\n",
    "        train_X_fa_masked = X[:,mask_beta]\n",
    "        test_X_fa_masked = test_X_fa_pc[:,mask_beta]\n",
    "    \n",
    "        clf.fit(train_X_fa_masked,Y)\n",
    "    \n",
    "        acc = clf.score(test_X_fa_masked,test_Y_fa)\n",
    "        acc_pool.append(acc)\n",
    "    \n",
    "    index = acc_pool.argmax()\n",
    "    beta_cutoff = beta_cutoff_pool[index]\n",
    "    \n",
    "    mask_beta = (abs(LR_beta_mean) > beta_cutoff)\n",
    "    train_X_fa_masked = X[:,mask_beta]\n",
    "    # now the PCs that should be reduced according to the newly bootstraped data distribution is determined \n",
    "    \n",
    "    clf.fit(train_X_fa_masked,Y)\n",
    "    coef = clf.coef_[0]\n",
    "    coef_modified = mask_back(mask_beta,coef,mask_type='beta')\n",
    "    inverse_coef= pca.inverse_transform(coef_modified)\n",
    "    coef_mni = mask_back(mask_NaN,inverse_coef,mask_type='mni')\n",
    "    boot_coef = np.vstack((boot_coef,coef_mni))\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'This is iteration {iteration}, using time {end-start}s.')\n",
    "boot_coef = boot_coef[1:,:]\n",
    "\n",
    "full_end = time.time()\n",
    "print(f'The total time cost is {full_end-full_start}s.')\n",
    "\n",
    "# save bootstrap_1000 distribution \n",
    "np.save(os.path.join(save_path,'bootstrap','train_fa_bootstrap.npy'),boot_coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
